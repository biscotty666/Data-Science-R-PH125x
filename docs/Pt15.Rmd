---
title: "15 Statistical inference"
output:
  html_document:
    df_print: paged
    css: "style.css"
    toc: true
---

[Book](http://rafalab.dfci.harvard.edu/dsbook/r-basics.html)

R commands in this chapter

In Chapter 16 we will describe, in some detail, how poll aggregators such as FiveThirtyEight use data to predict election outcomes. To understand how they do this, we first need to learn the basics of Statistical Inference, the part of statistics that helps distinguish patterns arising from signal from those arising from chance. Statistical inference is a broad topic and here we go over the very basics using polls as a motivating example. To describe the concepts, we complement the mathematical formulas with Monte Carlo simulations and R code.

```{r, echo=FALSE}
library(tidyverse)
library(dslabs)
img_path <- "inference/img/"
```

# 15.1 Polls

Opinion polling has been conducted since the 19th century. The general goal is to describe the opinions held by a specific population on a given set of topics. In recent times, these polls have been pervasive during presidential elections. Polls are useful when interviewing every member of a particular population is logistically impossible. <span class="green">The general strategy is to interview a smaller group, chosen at random, and then infer the opinions of the entire population from the opinions of the smaller group.</span> Statistical theory is used to justify the process. <span class="purple">This theory is referred to as inference and it is the main topic of this chapter.</span>

Elections are a particularly interesting case of opinion polls because the actual opinion of the entire population is revealed on election day. Of course, it costs millions of dollars to run an actual election which makes polling a cost effective strategy for those that want to forecast the results.

Real Clear Politics^[http://www.realclearpolitics.com] is an example of a news aggregator that organizes and publishes poll results. For example, they present the following poll results reporting estimates of the popular vote for the 2016 presidential election^[http://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html]:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#knitr::include_graphics(file.path(img_path,"rcp-polls.png"))
#url <- "https://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html"

url <- "https://web.archive.org/web/20161108012231/https://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html"
library(rvest)
tab <- read_html(url) |> html_elements("table")
tab <- tab[[1]] |> html_table() |> 
  mutate(Poll = stringr::str_remove(Poll, "\\/.*")) |>
  mutate(Poll = case_when(
    Poll == "BloombergBloomberg" ~ "Bloomberg",
    Poll == "FOX NewsFOX News" ~ "FOX News",
    Poll == "MonmouthMonmouth"  ~ "Monmouth",  
    Poll == "CBS NewsCBS News" ~ "CBS News",
    TRUE ~ Poll))
names(tab) <- stringr::str_remove_all(names(tab), "\\s(.*)")    
tab
```
(Source: [Real Clear Politics](https://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html))

Although in the United States the popular vote does not determine the result of the presidential election, we will use it as an illustrative and simple example of how well polls work. Forecasting the election is a more complex process since it involves combining results from 50 states and DC and we describe it in Section \@ref(election-forecasting).

Let's make some observations about the table above. First, note that

- different polls, all taken days before the election, report a different _spread_:  the estimated difference between support for the two candidates. 
- the reported spreads hover around what ended up being the actual result: Clinton won the popular vote by 2.1%. We also see a column titled **MoE** which stands for _margin of error_. 

In this section:

- Statistical concepts necessary to define _estimates_ and _margins of errors_
- Forecast final results and provide an estimate of the precision of our forecast
- _confidence intervals_ and _p-values_
- Bayesian modeling

In the final sections, we put it all together to recreate the simplified version of the FiveThirtyEight model and apply it to the 2016 election. 

We start by connecting probability theory to the task of using polls to learn about a population.

### The sampling model for polls

To help us understand the connection between polls and what we have learned, let's construct a similar situation to the one pollsters face. To mimic the challenge real pollsters face in terms of competing with other pollsters for media attention, we will use an urn full of beads to represent  voters and pretend we are competing for a \$25 dollar prize. The challenge is to guess the spread between the proportion of blue and red beads in this urn (in this case, a pickle jar):

<img src="img/urn.jpg" />

Before making a prediction, you can take a sample (with replacement) from the urn. To mimic the fact that running polls is expensive, it costs you \$0.10 per each bead you sample. Therefore, if your sample size is 250, and you win, you will break even since you will pay \$25 to collect your \$25 prize. Your entry into the competition can be an interval. If the interval you submit contains the true proportion, you get half what you paid and pass to the second phase of the competition. In the second phase, the entry with the smallest interval is selected as the winner. 

The __dslabs__ package includes a function that shows a random draw from this urn:
```{r}
set.seed(1)
library(tidyverse)
library(dslabs)
rafalib::mypar()
take_poll(25)
```




































