---
title: "9 Visualizing data distributions"
output:
  html_document:
    df_print: paged
    css: "style.css"
    toc: true
---

[Book](http://rafalab.dfci.harvard.edu/dsbook/r-basics.html)

R commands in this chapter

|[`cur_column`](#n)|
[`cur_group`](#n)|
[`cur_group_id`](#n)|
[`cur_group_rows`](#n)|
[`dnorm`](#norm)|
[`geom_bar`](#geom_bar)|
[`geom_boxplot`](#geom_boxplot)|
[`geom_density`](#geom_density)|
[`geom_histogram`](#geom_histogram)|
[`geom_qq`](#geom_qq)|
[`geom_raster`](#geom_raster)|
[`geom_tile`](#geom_tile)|
[`I`](#I)|
[`n`](#n)|
[`pnorm`](#norm)|
[`prop.table`](#prop.table)|
[`qnorm`](#norm)|
[`qplot`](#qplot)|
[`rnorm`](#norm)|
[`scale_fill_gradient`](#scale_fill_gradient)|
[`stat_ecdf`](#stat_ecdf)|

cur_group() gives the group keys, a tibble with one row and one column for each grouping variable.

cur_group_id() gives a unique numeric identifier for the current group.

cur_group_rows() gives the row indices for the current group.

cur_column() 

You may have noticed that numerical data is often summarized with the average value. For example, the quality of a high school is sometimes summarized with one number: the average score on a standardized test. Occasionally, a second number is reported: the standard deviation. For example, you might read a report stating that scores were 680 plus or minus 50 (the standard deviation). The report has summarized an entire vector of scores with just two numbers. Is this appropriate? Is there any important piece of information that we are missing by only looking at this summary rather than the entire list?

Our first data visualization building block is learning to summarize lists of factors or numeric vectors. More often than not, the best way to share or explore this summary is through data visualization. The most basic statistical summary of a list of objects or numbers is its distribution. Once a data has been summarized as a distribution, there are several data visualization techniques to effectively relay this information. For this reason, it is important to have a deep understand the concept of a distribution.

In this chapter, we first discuss properties of a variety of distributions and how to visualize distributions using a motivating example of student heights. We then discuss the **ggplot2** geometries for these visualizations in Section 9.8.

# 9.1 Variable types

The two main variables types are **categorical** and **numeric**. Each can be divided into two other groups: categorical can be ordinal or not, whereas numerical variables can be discrete or continuous. When each entry in a dataset comes from one of a small number of groups, we refer to the data as categorical data. Two simple examples are sex (male or female) and US regions (Northeast, South, North Central, West). Some categorical data can be ordered even if they are not numbers per se, such as spiciness (mild, medium, hot). In statistics textbooks, <span class="yellow">ordered categorical data are referred to as ordinal data</span>. Examples of numerical data are population sizes, murder rates, and heights. <span class="yellow">Some numerical data can be treated as ordered categorical. We can further divide numerical data into continuous and discrete.</span> Continuous variables are those that can take any value, such as heights, if measured with enough precision. For example, a pair of twins may be 68.12 and 68.11 inches, respectively. Counts, such as population sizes, are discrete because they have to be round numbers.

Keep in mind that discrete numeric data can be considered ordinal. Although this is technically true, <span class="yellow">we usually reserve the term ordinal data for variables belonging to a small number of different groups, with each group having many members. In contrast, when we have many groups with few cases in each group, we typically refer to them as discrete numerical variables.</span> So, for example, the number of packs of cigarettes a person smokes a day, rounded to the closest pack, would be considered ordinal, while the actual number of cigarettes would be considered a numerical variable. But, indeed, there are examples that can be considered both numerical and ordinal when it comes to visualizing data.

Here we focus on numeric variables because visualizing this data type is substantially more complex. However, we start by describing data visualization and summarization approaches for categorical data.

# 9.2 Case study: describing student heights

Pretend that we have to describe the heights of our classmates to ET, an extraterrestrial that has never seen humans. As a first step, we need to collect data. To do this, we ask students to report their heights in inches. We ask them to provide sex information because we know there are two different distributions by sex. We collect the data and save it in the `heights` data frame:

```{r}
library(tidyverse)
library(dslabs)
data(heights)
```
One way to convey the heights to ET is to simply send him this list of 1050 heights. But there are much more effective ways to convey this information, and understanding the concept of a distribution will be key. To simplify the explanation, we first focus on male heights. We examine the female height data in Section 9.6.

# 9.3 Distributions

The most basic statistical summary of a list of objects or numbers is its distribution. The simplest way to think of a distribution is as a compact description of a list with many entries. This concept should not be new for readers of this book. For example, with categorical data, the distribution simply describes the proportion of each unique category. The sex represented in the heights dataset is:
```{r}
prop.table(table(heights$sex))
```
<span class="yellow"><span id="prop.table">**`prop.table`**</span> Returns conditional proportions given margins, i.e. entries of x, divided by the appropriate marginal sums.</span>

This two-category frequency table is the simplest form of a distribution. We don’t really need to visualize it since one number describes everything we need to know: 23% are females and the rest are males. When there are more categories, then a simple barplot describes the distribution. Here is an example with US state regions:
```{r}
murders |>
  group_by(region) |>
  summarise(n = n()) |>
  mutate(Proportion = n/sum(n),
         region = reorder(region, Proportion)) |>
  ggplot(aes(x = region,
             y = Proportion,
             fill = region)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  xlab("")
```

**Information about the "current" group or variable**

<blockquote id="n">
These functions return information about the "current" group or "current" variable, so only work inside specific contexts like `summarise()` and `mutate()`.

- `n()` gives the current group size.
- `cur_group()` gives the group keys, a tibble with one row and one column for each grouping variable.
- `cur_group_id()` gives a unique numeric identifier for the current group.
- `cur_group_rows()` gives the row indices for the current group.
- `cur_column()` gives the name of the current column (in across() only).

See `group_data()` for equivalent functions that return values for all groups.
</blockquote>

This particular plot simply shows us four numbers, one for each category. <span class="yellow">We usually use barplots to display a few numbers.</span> Although this particular plot does not provide much more insight than a frequency table itself, it is a first example of how we convert a vector into a plot that succinctly summarizes all the information in the vector. When the data is numerical, the task of displaying distributions is more challenging.

## 9.3.1 Histograms

Numerical data that are not categorical also have distributions. However, in general, when data is not categorical, reporting the frequency of each entry, as we did for categorical data, is not an effective summary since most entries are unique. or example, in our case study, while several students reported a height of 68 inches, only one student reported a height of `68.503937007874` inches and only one student reported a height `68.8976377952756` inches. We assume that they converted from 174 and 175 centimeters, respectively.

Statistics textbooks teach us that a more useful way to define a distribution for numeric data is to define a function that reports the proportion of the data below $a$ for all possible values of $a$. This function is called the **emipirical cumulative distribution function (eCDF)**, it can be plotted, and it provides a full description of the distribution of our data. Here is the eCDF for male student heights:

```{r}
ds_theme_set()
heights |>
  filter(sex == "Male") |>
  ggplot(aes(height)) +
  stat_ecdf() +
  ylab("Proportion of heights less than or equal to a") +
  xlab("a")
```
**Compute empircal cumulative distribution** 

<blockquote id="stat_ecdf">
The empirical cumulative distribution function (ECDF) provides an alternative visualisation of distribution. Compared to other visualisations that rely on density (like geom_histogram()), the ECDF doesn't require any tuning parameters and handles both continuous and categorical variables. The downside is that it requires more training to accurately interpret, and the underlying visual tasks are somewhat more challenging.
</blockquote>

However, <span class="yellow">summarizing data by plotting the eCDF is actually not very popular in practice</span>. The main reason is that it does not easily convey characteristics of interest such as: at what value is the distribution centered? Is the distribution symmetric? What ranges contain 95% of the values?

*Histograms*, are much preferred because they greatly facilitate answering such questions. Histograms sacrifice just a bit of information to produce plots that are much easier to interpret. The simplest way to make a histogram is to divide the span of our data into non-overlapping bins of the same size. Then, for each bin, we count the number of values that fall in that interval. The histogram plots these counts as bars with the base of the bar defined by the intervals. Here is the histogram for the height data splitting the range of values into one inch intervals: $(49.5,50.5],(50.5,51.5],(51.5,52.5],(52.5,53.5],\dots,(82.5,83.5]$
```{r}
heights |>
  filter(sex == "Male") |>
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1,
                 color = "black")
```
As you can see in the figure above, <span class="yellow">a histogram is similar to a barplot, but it differs in that the x-axis is numerical, not categorical.</span>

If we send this plot to ET, he will immediately learn some important properties about our data. First, the range of the data is from 50 to 84 with the majority (more than 95%) between 63 and 75 inches. Second, the heights are close to symmetric around 69 inches. Also, by adding up counts, ET could obtain a very good approximation of the proportion of the data in any interval. Therefore, the histogram above is not only easy to interpret, but also provides almost all the information contained in the raw list of 812 heights with about 30 bin counts.

What information do we lose? Note that all values in each interval are treated the same when computing bin heights. So, for example, the histogram does not distinguish between 64, 64.1, and 64.2 inches. Given that these differences are almost unnoticeable to the eye, the practical implications are negligible and we were able to summarize the data to just 23 numbers.

We discuss how to code histograms in Section 9.8.

## 9.3.2 Smoothed density

*Smooth density* plots relay the same information as a histogram but are aesthetically more appealing. Here is what a smooth density plot looks like for our heights data:
```{r}
heights |> 
  filter(sex=="Male") |> 
  ggplot(aes(height)) + 
  geom_density(alpha = .2, 
               fill= "#00BFC4", 
               color = 0)  +
  geom_line(stat='density')
```

In this plot, we no longer have sharp edges at the interval boundaries and many of the local peaks have been removed. Also, <span class="yellow">the scale of the y-axis changed from counts to density.</span> To fully understand smooth densities, we have to understand *estimates*, a topic we don’t cover until later. Here we simply describe them as making the histograms prettier by drawing a curve that goes through the top of the histogream bars and then removing the bars. The values shown y-axis are chosen so that the area under the curve at up to 1. This implies that for any interval, the area under the curve for that interval gives us an approximation of how what proportion of the data is in the interval.

An advantage of smooth densities over histograms for visualization purposes is that densities make it easier to compare two distributions. This is in large part because the jagged edges of the histogram add clutter. Here is an example comparing male and female heights:
```{r}
heights |>
  ggplot(aes(height,
             fill = sex)) +
  geom_density(alpha = 0.2,
               color = 0) +
  geom_line(stat = "density")
```

With the right argument, **ggplot** automatically shades the intersecting region with a different color. We will show examples of **ggplot2** code for densities in Section 10 as well as Section 9.8.

## 9.3.3 The normal distribution

The normal distribution, also known as the bell curve and as the Gaussian distribution. Here is what the normal distribution looks like:
```{r}
mu <- 0
s <- 1
norm_dist <- 
  data.frame(x = seq(-4, 4, len=50)*s+mu) |>
  mutate(density = dnorm(x, mu, s))
norm_dist |>
  ggplot(aes(x, density)) +
  geom_line()
```
**Generate a normal distribution**

<blockquote id="norm">
- Probability density function: **`dnorm(x)`** where `x` is a vector of quantiles
- Cumulateive density function: **`pnorm(q)`** where `q` is a vector of quantiles
- Quantile function: **`qnorm(p)`** where `p` is a vector of probabilities
- Random generation: **`rnorm(n)`** where `n` is number of observations
</blockquote>


The normal distribution is one of the most famous mathematical concepts in history. A reason for this is that the distribution of many datasets can be approximated with normal distributions. These include including gambling winnings, heights, weights, blood pressure, standardized test scores, and experimental measurement errors. Statistical textbooks offer explanations for why this is the case. But how can the same distribution approximate datasets with completely different ranges for values, for example heights and weights? A second important characteristic of the normal distribution is that it can be adapted to different datasets by just adjusting two numbers, referred to as the average or mean and the standard deviation (SD). <span class="yellow">The normal distribution is symmetric, centered at what we refer to as the average, and most values (about 95%) are within 2 SDs from the average.</span> The plot above shows a normal distribution with average 0 and SD 1, often referred to as a **standard normal**. Note that the fact that <span class="yellow">because only two numbers are needed to adapt the normal distribution to a dataset, implies that if our data distribution is approximated by a normal distribution, all the information needed to describe the distribution can be encoded in just two numbers.</span> We now define these values for an arbitrary list of numbers.

Once we are convinced that our data, say it is stored in the vector `x`, has a distribution that is approximately normal we can find the specific one that matches our data by matching the average and SD of the data to the average and SD of the normal distribution, respectively. For a list of numbers contained in a vector `x`:
```{r}
index <- heights$sex == "Male"
x <- heights$height[index]
```
the average is defined as
```{r}
m <- sum(x) / length(x)
m
```
and the SD is defined as
```{r}
s <- sqrt(sum(x-mu^2) / length(x))
```
The pre-built functions mean and sd can be used here. (Note that, for reasons explained in statistics textbooks, `sd` divides by `length(x)-1` rather than `length(x)`)
```{r}
m <- mean(x)
s <- sd(x)
c(average = m, sd = s)
```
Here is a plot of the smooth density and the normal distribution with mean = 69.3 and SD = 3.6 plotted as a black line with our student height smooth density in blue:
```{r}
norm_dist <- 
  data.frame(x = seq(-4, 4, len = 50)*s + m) |>
  mutate(density = dnorm(x, m, s))
heights |>
  filter(sex == "Male") |>
  ggplot(aes(height)) +
  geom_density(fill = "#0099FF") +
  geom_line(aes(x, density),
            data = norm_dist,
            lwd = 1.5)
```

# 9.4 Boxplots

To understand boxplots we need to define some terms that are commonly used in exploratory data analysis.

The percentiles are the values for which $p=0.01,0.02,\dots,0.99$ of the data are less then or equal to that value, respectively. We call, for example, the case of $p=0.10$ the 10th percentile, which gives us a number for which 10% of the data is below. The most famous percentile is the 50th, also known as the median. Another special case that receives a name are the quartiles, which are obtained when setting $p=0.25,0.50,\text{ and } 0.75$, which are used by the boxplot.

To motivate boxplots we will go back to the US murder data. Suppose we want to summarize the murder rate distribution. Using the data visualization technique we have learned, we can quickly see that the normal approximation does not apply here:
```{r}
data(murders)
murders <-
  murders |>
  mutate(rate = total / population * 10^5)
library(gridExtra)
murders |>
  ggplot(aes(x = rate)) +
  geom_histogram(binwidth = 0.5,
                 color = "black") +
  ggtitle("Histogram")
```

In this case, the histogram above or a smooth density plot would serve as a relatively succinct summary.

Now suppose those used to receiving just two numbers as summaries ask us for a more compact numerical summary.

The boxplot provides a five-number summary composed of the range along with the quartiles (the 25th, 50th, and 75th percentiles). The R implementation of boxplots ignore *outliers* when computing the range and instead plot these as independent points. The help file provides a specific definition of outliers. The boxplot shows these numbers as a “box” with “whiskers”

```{r}
murders |>
  ggplot(aes("", rate)) +
  geom_boxplot() +
  coord_cartesian(xlim = c(0,2)) +
  xlab("")
```
with the box defined by the 25% and 75% percentile and the whiskers showing the range. The distance between these two is called the interquartile range. The two points are outliers according to the R implementation. The median is shown with a horizontal line.

From just this simple plot, we know that the median is about 2.5, that the distribution is not symmetric, and that the range is 0 to 5 for the great majority of states with two exceptions.

We discuss how to make boxplots in Section 9.8.

# 9.5 Stratification

In data analysis we often divide observations into groups based on the values of one or more variables associated with those observations. For example in the next section we divide the height values into groups based on a sex variable: females and males. We call this procedure **stratification** and refer to the resulting groups as strata.

Stratification is common in data visualization because we are often interested in how the distribution of variables differs across different subgroups. We will see several examples throughout this part of the book.

# 9.6 Case study: describing student heights (continued)

Using the histogram, density plots, and QQ-plots, we have become convinced that the male height data is well approximated with a normal distribution. In this case, we report back to ET a very succinct summary: male heights follow a normal distribution with an average of 69.3 inches and a SD of 3.6 inches. With this information, ET will have a good idea of what to expect when he meets our male students. However, to provide a complete picture we need to also provide a summary of the female heights.

We learned that boxplots are useful when we want to quickly compare two or more distributions. Here are the heights for men and women:

```{r}
heights |>
  ggplot(aes(x = sex, 
             y = height, 
             fill = sex)) +
  geom_boxplot()
```
The plot immediately reveals that males are, on average, taller than females. The standard deviations appear to be similar. But does the normal approximation also work for the female height data collected by the survey? We expect that they will follow a normal distribution, just like males. However, exploratory plots reveal that the approximation is not as useful:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill = "#F8766D")
```
We see something we did not see for the males: the density plot has a second “bump”. Also, the highest points tend to be taller than expected by the normal than expected heights for a normal distribution. When reporting back to ET, we might need to provide a histogram rather than just the average and standard deviation for the female heights.

However, go back and read Tukey’s quote. We have noticed what we didn’t expect to see. <span class="yellow">If we look at other female height distributions, we do find that they are well approximated with a normal distribution. So why are our female students different?</span> Is our class a requirement for the female basketball team? Are small proportions of females claiming to be taller than they are? Another, perhaps more likely, explanation is that in the form students used to enter their heights, `FEMALE` was the default sex and some males entered their heights, but forgot to change the sex variable. In any case, data visualization has helped discover a potential flaw in our data.

Regarding the five smallest values, note that these values are:
```{r}
heights |>
  filter(sex == "Female") |>
  slice_max(desc(height), n=5) |>
  pull(height)
```
NB. The text uses `top_n` which is deprecated.

Because these are reported heights, a possibility is that the student meant to enter `5'1"`, `5'2"`, `5'3"` or `5'5"`.

# 9.7 Exercises

1. Define variables containing the heights of males and females like this:
```{r}
library(dslabs)
data(heights)
male <- heights$height[heights$sex == "Male"]
female <- heights$height[heights$sex == "Female"]
```

How many measurements do we have for each?
```{r}
length(male)
length(female)
```

2. Suppose we can’t make a plot and want to compare the distributions side by side. We can’t just list all the numbers. Instead, we will look at the percentiles. Create a five row table showing female_percentiles and male_percentiles with the 10th, 30th, 50th, 70th, & 90th percentiles for each sex. Then create a data frame with these two as columns.
```{r}
heights |>
  filter(sex == "Female") |>
  summarise(Females = quantile(height, c(10, 30, 50, 70, 90)/100)) -> fh
heights |>
  filter(sex == "Male") |>
  summarise(Males = quantile(height, c(10, 30, 50, 70, 90)/100)) -> mh
Percentiles <- c("10th","30th","50th","70th","90th")
data.frame(Percentiles, fh, mh)
```

3. Study the following boxplots showing population sizes by country:
```{r}
library(tidyverse)
library(dslabs)
ds_theme_set()
data(gapminder)
gapminder |> 
  filter(year == 2010) |> 
  group_by(continent) |> 
  select(continent, population) -> tab 
tab |> ggplot(aes(x=continent, y=population/10^6)) + 
  geom_boxplot() + 
  scale_y_continuous(breaks = c(1,10,100,1000)) + 
  ylab("Population in millions")
```

Which continent has the country with the biggest population size?
<span class="yellow">Asia</span>

4. What continent has the largest median population size?
<span class="yellow">Africa</span>

5. What is median population size for Africa to the nearest million?
<span class="yellow">10M</span>

6. What proportion of countries in Europe have populations below 14 million?

a. 0.99
b. <span class="yellow">0.75</span>
c. 0.50
d. 0.25

7. If we use a log transformation, which continent shown above has the largest interquartile range?

```{r}
library(tidyverse)
library(dslabs)
ds_theme_set()
data(gapminder)
gapminder |> 
  filter(year == 2010) |> 
  group_by(continent) |> 
  select(continent, population) -> tab 
tab |> ggplot(aes(x=continent, y=population/10^6)) + 
  geom_boxplot() + 
  scale_y_continuous(trans = "log10",
                     breaks = c(1,10,100,1000)) + 
  ylab("Population in millions")
```
<span class="yellow">Americas</span>

8. Load the height data set and create a vector x with just the male heights:
```{r}
library(dslabs)
data(heights)
x <- heights$height[heights$sex=="Male"]
```
What proportion of the data is between 69 and 72 inches (taller than 69, but shorter or equal to 72)? Hint: use a logical operator and mean.
```{r}
heights |>
  filter(height < 69 & height <= 72) -> targets
tar_count <- length(targets)
tar_count / mean(heights$height)
```
<span class="yellow">29%</span>

# 9.8 ggplot2 geometries

## 9.8.1 Barplots

To generate a barplot we can use the <span id="geom_bar">**`geom_bar`**</span> geometry. The default is to count the number of each category and draw a bar. Here is the plot for the regions of the US.

```{r}
murders |>
  ggplot(aes(region)) +
  geom_bar()
```
We often already have a table with a distribution that we want to present as a barplot. Here is an example of such a table:
```{r}
data(murders)
murders |>
  count(region) |>
  mutate(proportion = n/sum(n)) -> tab
tab
```
We no longer want `geom_bar` to count, but rather just plot a bar to the height provided by the proportion variable. For this we need to provide `x` (the categories) and `y` (the values) and use the stat="identity" option.
```{r}
tab |>
  ggplot(aes(region, proportion)) + 
  geom_bar(stat = "identity")
```

## 9.8.2 Histograms {#geom_histogram}

To generate histograms we use **`geom_histogram`**. By looking at the help file for this function, we learn that the only required argument is `x`, the variable for which we will construct a histogram. We dropped the `x` because we know it is the first argument. The code looks like this:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_histogram()
```
We previously used a bin size of 1 inch, so the code looks like this:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1)
```
Finally, if for aesthetic reasons we want to add color, we use the arguments described in the help file. We also add labels and a title:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, fill="blue", col="black") +
  xlab("Female heights in inches") +
  ggtitle("Histogram")
```

## 9.8.3 Density plots {#geom_density}

To create a smooth density, we use the **`geom_density`**. To make a smooth density plot with the data previously shown as a histogram we can use this code:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill = "blue")
```
To change the smoothness of the density, we use the **adjust** argument to multiply the default value by that adjust. For example, if we want the bandwidth to be twice as big we use:
```{r}
heights |>
  filter(sex == "Female") |>
  ggplot(aes(height)) +
  geom_density(fill = "blue",
               adjust = 2)
```

## 9.8.4 Boxplots {#geom_boxplot}

The geometry for boxplot is **`geom_boxplot`**. As discussed, boxplots are useful for comparing distributions. For example, below are the previously shown heights for women, but compared to men. For this geometry, we need arguments x as the categories, and y as the values.

```{r}
heights |> 
  ggplot(aes(sex,height)) +
  geom_boxplot()
```

## QQ-plots {#geom_qq}

For qq-plots we use the **`geom_qq`** geometry. From the help file, we learn that we need to specify the `sample` (we will learn about samples in a later chapter). Here is the `qqplot` for men heights.


```{r}
heights |>
  filter(sex == "Male") |>
  ggplot(aes(sample = height)) +
  geom_qq() +
  geom_qq_line()
```
By default, the sample variable is compared to a normal distribution with average 0 and standard deviation 1. To change this, we use the `dparams` arguments based on the help file. Adding an identity line is as simple as assigning another layer. For straight lines, we use the `geom_abline` function. The default line is the identity line (slope = 1, intercept = 0).
```{r}
params <- 
  heights |>
  filter(sex == "Male") |>
  summarise(mean = mean(height),
            sd = sd(height))
heights |>
  filter(sex == "Male") |>
  ggplot(aes(sample = height)) +
  geom_qq(dparams = params) +
  geom_abline()
```
Another option here is to scale the data first and then make a qqplot against the standard normal. 
```{r}
heights |>
  filter(sex == "Male") |>
  ggplot(aes(sample = scale(height))) +
  geom_qq() +
  geom_abline()
```

## 9.8.5 Images

Images were not needed for the concepts described in this chapter, but we will use images in Section 11.14, so we introduce the two geometries used to create images: <span id="geom_tile">**`geom_tile`**</span> and <span id="geom_raster">**`geom_raster`**</span>. They behave similarly; to see how they differ, please consult the help file. To create an image in **ggplot2** we need a data frame with the x and y coordinates as well as the values associated with each of these. Here is a data frame.
```{r}
x <- expand.grid(x = 1:12, y = 1:10) |>
  mutate(z = 1:120)
x
```
<span class="yellow">Note that this is the tidy version of a matrix, matrix(1:120, 12, 10).</span> To plot the image we use the following code:
```{r}
x |>
  ggplot(aes(x, y, fill = z)) +
  geom_raster()
```
With these images you will often want to change the color scale. This can be done through the <span id="scale_fill_gradient">**`scale_fill_gradient`**</span> layer.
```{r}
x |> 
  ggplot(aes(x, y, fill = z)) + 
  geom_raster() + 
  scale_fill_gradientn(colors =  terrain.colors(10))
x
```
NB from the docs
<blockquote>
`geom_rect` and `geom_til`e do the same thing, but are parameterised differently: `geom_rect` uses the locations of the four corners (`xmin`, `xmax`, `ymin` and `ymax`), while `geom_tile` uses the center of the tile and its size (`x`, `y`, `width`, `height`). `geom_raster` is a high performance special case for when all the tiles are the same size.
</blockquote>

## 9.8.6 Quick plots

In Section 8.13 we introduced <span id="qplot">**`qplot`**</span> as a useful function when we need to make a quick scatterplot. We can also use `qplot` to make histograms, density plots, boxplot, qqplots and more. Although it does not provide the level of control of ggplot, `qplot` is definitely useful as it permits us to make a plot with a short snippet of code.

Suppose we have the female heights in an object `x`:
```{r}
heights |>
  filter(sex == "Male") |>
  pull(height) -> x
qplot(x)
```
<span class="yellow">The function guesses that we want to make a histogram because we only supplied one variable.</span> In Section 8.13 we saw that if we supply `qplot` two variables, it automatically makes a scatterplot.

To make a quick `qqplot` you have to use the sample argument. Note that we can add layers just as we do with ggplot.
```{r}
qplot(sample = scale(x)) +
  geom_abline()
```
If we supply a factor and a numeric vector, we obtain a plot like the one below. Note that in the code below we are using the data argument. <span class="yellow">Because the data frame is not the first argument in qplot, we have to use the dot operator.</span>
```{r}
height <- heights |> pull(height)
sex <- heights |> pull(sex)
qplot(sex, height)
```
NB. <span class="yellow">The code above is different from the code in the book, which is `heights |> qplot(sex, height, data = .)`. This failed with "Object "." not found. I can't be certain that the plot above is the intended one, but it seems to be.</span>

We can also select a specific geometry by using the `geom` argument. So to convert the plot above to a boxplot, we use the following code:
```{r}
sex <- heights |> pull(sex)
qplot(sex, height, geom = "boxplot")
```
We can also use the `geom` argument to generate a density plot instead of a histogram:
```{r}
qplot(x, geom = "density")
```
Although not as much as with ggplot, we do have some flexibility to improve the results of qplot. Looking at the help file we see several ways in which we can improve the look of the histogram above. Here is an example:
```{r}
qplot(x, 
      bins = 15,
      color = I("black"),
      xlab = "Population")
```
NB. from the docs for <span id="I">**`I()`**</span>, the `as is` function
<blockquote>
Protecting an object by enclosing it in `I()` in a call to **data.frame** inhibits the conversion of character vectors to factors and the dropping of names, and ensures that matrices are inserted as single columns.
</blockquote>























