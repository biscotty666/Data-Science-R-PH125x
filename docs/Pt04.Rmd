---
title: "4 The tidyverse"
output:
  html_document:
    df_print: paged
    css: "style.css"
    toc: true
---

[Book](http://rafalab.dfci.harvard.edu/dsbook/r-basics.html)

# Functions in this chapter

[`arrange`](#arrange)|
[`as_tibble`](#as_tibble)|
[`between`](#between)|
[`case_when`](#case_when)|
[`filter`](#filter)|
[`group_by`](#group_by)|
[`mutate`](#mutate)|
[`%>%` or `|>`](#the-pipe)|
[`pull`](#pull)|
[`quantile`](#quantile)|
[`rank`](#rank)|
[`sapply`](#sapply)|
[`select`](#select)|
[`slice_max`](#slices)|
[`slice_min`](#slices)|
[`summarize`](#summarize)|
[`tibble`](#tibble)|

Up to now we have been manipulating vectors by reordering and subsetting them through indexing. However, once we start more advanced analyses, the preferred unit for data storage is not the vector but the data frame. In this chapter we learn to work directly with data frames, which greatly facilitate the organization of information. We will be using data frames for the majority of this book. We will focus on a specific data format referred to as **tidy** and on specific collection of packages that are particularly helpful for working with tidy data referred to as the **tidyverse**.

```{r}
library(tidyverse)
```

We will learn how to implement the tidyverse approach throughout the book, but before delving into the details, in this chapter we introduce some of the most widely used tidyverse functionality, starting with the **dplyr** package for manipulating data frames and the **purrr** package for working with functions. Note that the tidyverse also includes a graphing package, **ggplot2**, which we introduce later in Chapter 8 in the Data Visualization part of the book; the **readr** package discussed in Chapter 5; and many others. In this chapter, we first introduce the concept of tidy data and then demonstrate how we use the tidyverse to work with data frames in this format.

# 4.1 Tidy data

We say that a data table is in tidy format if each row represents one observation and columns represent the different variables available for each of these observations. The murders dataset is an example of a tidy data frame.

```{r}
library(dslabs)
data(murders)
head(murders)
```

Each row represent a state with each of the five columns providing a different variable related to these states: name, abbreviation, region, population, and total murders.

To see how the same information can be provided in different formats, consider the following example:

```
#>       country year fertility
#> 1     Germany 1960      2.41
#> 2 South Korea 1960      6.16
#> 3     Germany 1961      2.44
#> 4 South Korea 1961      5.99
#> 5     Germany 1962      2.47
#> 6 South Korea 1962      5.79
```

This tidy dataset provides fertility rates for two countries across the years. This is a tidy dataset because each row presents one observation with the three variables being country, year, and fertility rate. However, this dataset originally came in another format and was reshaped for the dslabs package. Originally, the data was in the following format:

```
#>       country 1960 1961 1962
#> 1     Germany 2.41 2.44 2.47
#> 2 South Korea 6.16 5.99 5.79
```
The same information is provided, but there are two important differences in the format: 1) each row includes several observations and 2) one of the variables, year, is stored in the header. For the tidyverse packages to be optimally used, data need to be reshaped into tidy format, which you will learn to do in the Data Wrangling part of the book. Until then, we will use example datasets that are already in tidy format.

Although not immediately obvious, as you go through the book you will start to appreciate the advantages of working in a framework in which functions use tidy formats for both inputs and outputs. You will see how this permits the data analyst to focus on more important aspects of the analysis rather than the format of the data.

# 4.2 Exercises

1. Examine the built-in dataset `co2`. Which of the following is true:

  a. `co2` is tidy data: it has one year for each row.
  b. `co2` is not tidy: we need at least one column with a character vector.
  c. `co2` is not tidy: it is a matrix instead of a data frame.
  d. `co2` is not tidy: to be tidy we would have to wrangle it to have three columns (year, month and value), then each co2 observation would have a row.
  
d

```{r}
# co2
```


2. Examine the built-in dataset `ChickWeight`. Which of the following is true:

  a. `ChickWeight` is not tidy: each chick has more than one row.
  b. `ChickWeight` is tidy: each observation (a weight) is represented by one row. The chick from which this measurement came is one of the variables.
  c. `ChickWeight` is not tidy: we are missing the year column.
  d.` ChickWeight` is tidy: it is stored in a data frame.
  
```{r}
class(ChickWeight)
```

d

3. Examine the built-in dataset `BOD`. Which of the following is true:

  a. `BOD` is not tidy: it only has six rows.
  b. `BOD` is not tidy: the first column is just an index.
  c. `BOD` is tidy: each row is an observation with two values (time and demand)
  d. `BOD` is tidy: all small datasets are tidy by definition.
  
```{r}
BOD
```

c
  
4. Which of the following built-in datasets is tidy (you can pick more than one):

 a. BJsales No
 b. EuStockMarkets Yes
 c. DNase Yes
 d. Formaldehyde Yes
 e. Orange Yes
 f. UCBAdmissions No

# 4.3 Manipulating data frames

## 4.3.1 `mutate()`: Add columns {#mutate}

We want all the necessary information for our analysis to be included in the data table. So the first task is to add the murder rates to our murders data frame. The function mutate takes the data frame as a first argument and the name and values of the variable as a second argument using the convention name = values. So, to add murder rates, we use:

```{r}
library(dslabs)
data("murders")
murders <- mutate(murders, 
                  rate = total / population * 10^5)
head(murders)
```

## 4.3.2 Subsetting with `filter()` {#filter}

```{r}
filter(murders, rate <= 0.71)
```

## 4.3.3 Selecting columns with `select()` {#select}

```{r}
new_table <- select(murders, state, region, rate)
filter(new_table, rate <= 0.71)
```

# 4.4 Exercises

1. Load the `dplyr` package and the `murders` dataset.

```{r}
library(dplyr)
library(dslabs)
data(murders)
```

Use the function mutate to add a murders column named rate with the per 100,000 murder rate as in the example code above. Make sure you redefine murders as done in the example code above ( murders <- [your code]) so we can keep using this variable.

```{r}
murders <- mutate(murders,
                  rate = total / population * 10^5)
head(murders)
```

2. If <span id="rank">`rank(x)`</span> gives you the ranks of x from lowest to highest, `rank(-x)` gives you the ranks from highest to lowest. Use the function `mutate` to add a column rank containing the rank, from highest to lowest murder rate. Make sure you redefine murders so we can keep using this variable.

```{r}
murders <- mutate(murders,
       rank = rank(-murders$total))
head(murders)
```

3. With `dplyr`, we can use select to show only certain columns. For example, with this code we would only show the states and population sizes:

`select(murders, state, population) |> head()`

Use `select` to show the state names and abbreviations in `murders`. Do not redefine `murders`, just show the results.

```{r}
select(murders, state, abb) |> head()
```


4. The `dplyr` function `filter` is used to choose specific rows of the data frame to keep. Unlike `select` which is for columns, filter is for rows. For example, you can show just the New York row like this:

`filter(murders, state == "New York")`

You can use other logical vectors to filter rows.

Use filter to show the top 5 states with the highest murder rates. After we add murder rate and rank, do not change the murders dataset, just show the result. Remember that you can filter based on the rank column.

```{r}
filter(murders, rank <= 5.0)
```

5. We can remove rows using the != operator. For example, to remove Florida, we would do this:

`no_florida <- filter(murders, state != "Florida")`
Create a new data frame called no_south that removes states from the South region. How many states are in this category? You can use the function nrow for this.

```{r}
no_south <- filter(murders, region != "South")
nrow(no_south)
```

6. We can also use `%in%` to `filter` with `dplyr`. You can therefore see the data from New York and Texas like this:

`filter(murders, state %in% c("New York", "Texas"))`

Create a new data frame called `murders_nw` with only the states from the Northeast and the West. How many states are in this category?

```{r}
murders_nw <- filter(murders, region %in% c("Northeast", "South"))
nrow(murders_nw)
```

7. Suppose you want to live in the Northeast or West and want the murder rate to be less than 1. We want to see the data for the states satisfying these options. Note that you can use logical operators with `filter`. Here is an example in which we filter to keep only small states in the Northeast region.

`filter(murders, population < 5000000 & region == "Northeast")`

Make sure murders has been defined with rate and rank and still has all states. Create a table called my_states that contains rows for states satisfying both the conditions: it is in the Northeast or West and the murder rate is less than 1. Use select to show only the state name, the rate, and the rank.

```{r}
murders |> 
  filter(rate < 1 & region %in% c("Northeast", "West")) |>
  select(state, rate, rank)
```

# 4.5 The pipe: `|>` or `%>%` {#the-pipe}


```{r}
murders |> 
  select(state, region, rate) |>
  filter(rate <= 0.71)
```

```{r}
16 |> sqrt() |> log2()
```

# 4.6 Exercises

1. The pipe `|>` can be used to perform operations sequentially without having to define intermediate objects. Start by redefining murder to include rate and rank.

```{r}
murders <- mutate(murders, rate =  total / population * 100000, 
                  rank = rank(-rate))
```
In the solution to the previous exercise, we did the following:

```
my_states <- filter(murders, region %in% c("Northeast", "West") & 
                      rate < 1)

select(my_states, state, rate, rank)
```
The pipe `|>` permits us to perform both operations sequentially without having to define an intermediate variable my_states. We therefore could have mutated and selected in the same line like this:

```
mutate(murders, rate =  total / population * 100000, 
       rank = rank(-rate)) |>
  select(state, rate, rank)
```
Notice that select no longer has a data frame as the first argument. The first argument is assumed to be the result of the operation conducted right before the `|>`.

Repeat the previous exercise, but now instead of creating a new object, show the result and only include the state, rate, and rank columns. Use a pipe |> to do this in just one line.

```{r}
murders |>
  mutate(rate = total / population * 10^5,
         rank = rank(-rate)) |>
  filter(region %in% c("Northeast", "West") &
           rate < 1) |>
  select(state, rate, rank) -> my_states
my_states
```


2. Reset murders to the original table by using data(murders). Use a pipe to create a new data frame called my_states that considers only states in the Northeast or West which have a murder rate lower than 1, and contains only the state, rate and rank columns. The pipe should also have four components separated by three |>. The code should look something like this:
```
my_states <- murders |>
  mutate SOMETHING |> 
  filter SOMETHING |> 
  select SOMETHING
```
# 4.7 Summarizing data

An important part of exploratory data analysis is summarizing data. The average and standard deviation are two examples of widely used summary statistics. More informative summaries can often be achieved by first splitting data into groups. In this section, we cover two new dplyr verbs that make these computations easier: summarize and group_by. We learn to access resulting values using the pull function.

## 4.7.1 `summarize()` {#summarize}

```{r}
library(dplyr)
library(dslabs)
data(heights)
head(heights)
```

The following code computes the average and standard deviation for females:

```{r}
s <- heights |>
  filter(sex == "Female") |>
  summarise(average = mean(height), standard_deviation = sd(height))
s
```

```{r}
s$average
s$standard_deviation
```

For another example of how we can use the summarize function, let’s compute the average murder rate for the United States. Remember our data table includes total murders and population size for each state and we have already used dplyr to add a murder rate column:

```
murders <- murders |> mutate(rate = total/population*100000)
```

Remember that the US murder rate is **not** the average of the state murder rates:

```{r}
summarise(murders, mean(rate))
```

This is because in the computation above the small states are given the same weight as the large ones. The US murder rate is the total number of murders in the US divided by the total US population. So the correct computation is:

```{r}
us_murder_rate <- murders |>
  summarise(rate = sum(total) / sum(population) * 100000)
us_murder_rate
```

## 4.7.2 Multiple summaries {#quantile}

Suppose we want three summaries from the same variable such as the median, minimum, and maximum heights. `quantile(x, c(0.5, 0, 1))` returns the median (50th percentile), the min (0th percentile), and max (100th percentile) of the vector `x`. We can use it with summarize like this:

```{r}
heights |>
  filter(sex == "Female") |>
  summarise(median_min_max = quantile(height, c(0.5, 0, 1)))
```
However, notice that the summaries are returned in a row each. To obtain the results in different columns, we have to define a function that returns a data frame like this:

```{r}
median_min_max <- function(x) {
  qs <- quantile(x, c(0.5, 0, 1))
  data.frame(median = qs[1],
             minimum = qs[2],
             maximum = qs[3])
}
heights |>
  filter(sex == "Female") |>
  summarise(median_min_max(height))
```

## 4.7.3 Group then summarize with `group_by()` {#group_by}

```{r}
heights |> group_by(sex)
```

The result does not look very different from heights, <span class="blue">except we see Groups: sex [2] when we print the object</span>. Although not immediately obvious from its appearance, <span class="blue">this is now a special data frame called a grouped data frame,</span> and `dplyr` functions, in particular `summarize`, will behave differently when acting on this object. Conceptually, you can think of this table as many tables, with the same columns but not necessarily the same number of rows, stacked together in one object. When we summarize the data after grouping, this is what happens:

```{r}
heights |>
  group_by(sex) |>
  summarise(average = mean(height), standard_deviation = sd(height))
```
The summarize function applies the summarization to each group separately.

For another example, let’s compute the median, minimum, and maximum murder rate in the four regions of the country using the `median_min_max` defined above:

```{r}
murders |>
  group_by(region) |>
  summarise(median_min_max(rate))
```

# 4.8 `pull()` {#pull}

The `us_murder_rate` object defined above represents just one number. Yet we are storing it in a data frame:

```{r}
class(us_murder_rate)
```

since, <span class="blue">as most `dplyr` functions, `summarize` always returns a data frame.</span>

This might be problematic if we want to use this result with functions that require a numeric value. Here we show a useful trick for accessing values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the pull function. To understand what we mean take a look at this line of code:

```{r}
us_murder_rate |> pull(rate)
```

This returns the value in the `rate` column of `us_murder_rate` <span class="blue">making it equivalent to `us_murder_rate$rate`.</span>

To get a number from the original data table with one line of code we can type:

```{r}
us_murder_rate <- murders |>
  summarise(rate = sum(total) / sum(population) * 10^5) |>
  pull(rate)

us_murder_rate
```
```{r}
class(us_murder_rate)
```

# 4.9 Sorting data frames: 'arrange()` {#arrange}

When examining a dataset, it is often convenient to sort the table by the different columns. We know about the `order` and `sort` function, but for ordering entire tables, the `dplyr` function `arrange` is useful. For example, here we order the states by population size:

```{r}
murders |>
  arrange(population) |>
  head()
```
With `arrange` we get to decide which column to sort by. To see the states by murder rate, from lowest to highest, we arrange by `rate` instead:

```{r}
murders |>
  arrange(rate) |>
  head()
```
Note that the default behavior is to order in ascending order. In `dplyr`, the function <span id="desc">`desc`</span> transforms a vector so that it is in descending order. To <span class="blue">sort the table in descending order</span>, we can type:

```{r}
murders |>
  arrange(desc(rate)) |>
  head()
```

## 4.9.1 Nested sorting

If we are ordering by a column with ties, we can use a second column to break the tie. Similarly, a third column can be used to break ties between first and second and so on. Here we order by region, then within region we order by murder rate:
```{r}
murders |>
  arrange(region, rate) |>
  head()
```

## 4.9.2 The top $n$ {#top_n}

In the code above, we have used the function `head` to avoid having the page fill up with the entire dataset. If we want to see a larger proportion, we can use the `top_n` function. This function takes a data frame as it’s first argument, the number of rows to show in the second, and the variable to filter by in the third. Here is an example of how to see the top 5 rows:

```{r}
murders |>
  top_n(5, rate)
```
Note that rows are not sorted by rate, only filtered. If we want to sort, we need to use arrange. Note that if the third argument is left blank, top_n filters by the last column.

From the docs:

**[Superseded] top_n() has been superseded in favour of <span id="slices">`slice_min()`/`slice_max()`</span>. While it will not be deprecated in the near future, retirement means that we will only perform critical bug fixes, so we recommend moving to the newer alternatives.**

```{r}
murders |>
  slice_max(rate, n = 5)
```

# 4.10 Exercises

For these exercises, we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). This center has conducted a series of health and nutrition surveys since the 1960’s. Starting in 1999, about 5,000 individuals of all ages have been interviewed every year and they complete the health examination component of the survey. Part of the data is made available via the **NHANES** package.

```{r}
# install.packages("NHANES")
library(NHANES)
data(NHANES)
```

The NHANES data has many missing values. The `mean` and `sd` functions in R will return `NA` if any of the entries of the input vector is an `NA`. Here is an example:
```{r}
library(dslabs)
data(na_example)
mean(na_example)
sd(na_example)
```
To ignore the NAs we can use the `na.rm` argument:
```{r}
mean(na_example, na.rm = TRUE)
sd(na_example, na.rm = TRUE)
```
Let’s now explore the NHANES data.

1. We will provide some basic facts about blood pressure. First let’s select a group to set the standard. We will use 20-to-29-year-old females. `AgeDecade` is a categorical variable with these ages. Note that the category is coded like ” 20-29”, with a space in front! What is the average and standard deviation of systolic blood pressure as saved in the BPSysAve variable? Save it to a variable called ref.

```{r}
NHANES |>
  head()
```

```{r}
ref <- NHANES |>
  filter(AgeDecade == " 20-29") |>
  summarise(mean(BPSysAve, na.rm = TRUE))
ref
```


Hint: Use filter and summarize and use the na.rm = TRUE argument when computing the average and standard deviation. You can also filter the NA values using filter.

2. Using a pipe, assign the average to a numeric variable ref_avg. Hint: Use the code similar to above and then pull.

```{r}
ref_avg <- NHANES |>
  filter(AgeDecade == " 20-29") |>
  pull(BPSysAve) |>
  mean(na.rm = TRUE)
ref_avg
```
3. Now report the min and max values for the same group.

```{r}
ref_min <- NHANES |>
  filter(AgeDecade == " 20-29") |>
  pull(BPSysAve) |>
  min(na.rm = TRUE)
ref_min
ref_max <- NHANES |>
  filter(AgeDecade == " 20-29") |>
  pull(BPSysAve) |>
  max(na.rm = TRUE)
ref_max
```

4. Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in question 1. Note that the age groups are defined by AgeDecade. Hint: rather than filtering by age and gender, filter by Gender and then use group_by.

```{r}
NHANES |>
  filter(Gender == "female") |>
  group_by(AgeDecade) |>
  summarise(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
```
5. Repeat exercise 4 for males.

```{r}
NHANES |>
  filter(Gender == "male") |>
  group_by(AgeDecade) |>
  summarise(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
```

6. We can actually combine both summaries for exercises 4 and 5 into one line of code. This is because group_by permits us to group by more than one variable. Obtain one big summary table using group_by(AgeDecade, Gender).

```{r}
NHANES |>
  group_by(Gender, AgeDecade) |>
  summarise(average = mean(BPSysAve, na.rm = TRUE), standard_deviation = sd(BPSysAve, na.rm = TRUE))
```

7. For males between the ages of 40-49, compare systolic blood pressure across race as reported in the Race1 variable. Order the resulting table from lowest to highest average systolic blood pressure.

```{r}
NHANES |>
  filter(Gender == "male", AgeDecade == " 40-49") |>
  group_by(Race1)|>
  summarise(average = mean(BPSysAve, na.rm = TRUE), 
            standard_deviation = sd(BPSysAve, na.rm = TRUE)) |>
  arrange(average)
```

# 4.11 Tibbles

Tidy data must be stored in data frames. We introduced the data frame in Section 2.4.1 and have been using the `murders` data frame throughout the book. In Section 4.7.3 we introduced the `group_by` function, which permits stratifying data before computing summary statistics. But where is the group information stored in the data frame?

```{r}
murders |> group_by(region)
```
```{r}
murders |> group_by(region) |> class()
```
The `tbl`, pronounced tibble, is a special kind of data frame. <span class="blue">The functions `group_by` and `summarize` always return this type of data frame.</span> The `group_by` function returns a special kind of tbl, the **`grouped_df`**. We will say more about these later. For consistency, the `dplyr` manipulation verbs (`select`, `filter`, `mutate`, and `arrange`) preserve the class of the input: if they receive a regular data frame they return a regular data frame, while if they receive a tibble they return a tibble. But tibbles are the preferred format in the tidyverse and as a result tidyverse functions that produce a data frame from scratch return a tibble. For example, in Chapter 5 we will see that tidyverse functions used to import data create tibbles.

Tibbles are very similar to data frames. In fact, you can think of them as a modern version of data frames. Nonetheless there are three important differences which we describe next.

## 4.11.1 Tibbles display better

The print method for tibbles is more readable than that of a data frame. To see this, compare the outputs of typing `murders` and the output of `murders` if we convert it to a tibble. We can do this using <span id="as_tibble">`as_tibble(murders)`</span>. If using RStudio, output for a tibble adjusts to your window size. To see this, change the width of your R console and notice how more/less columns are shown.

```{r}
murders
```
```{r}
as_tibble(murders)
```

## 4.11.2 Subsets of tibbles are tibbles

If you subset the columns of a data frame, you may get back an object that is not a data frame, such as a vector or scalar. For example:

```{r}
class(murders[,4])
```
```{r}
class(as_tibble(murders[,4]))
```
A related feature is that tibbles will give you a warning if you try to access a column that does not exist. If we accidentally write Population instead of population this:

```{r}
murders$Population
```
```{r}
as_tibble(murders)$Poplation
```

## 4.11.3 Tibbles can have complex entries

```{r}
tibble(id=c(1, 2, 3), func = c(mean, median, sd))
```
## 4.11.4 Tibbles can be grouped

The function `group_by` returns a special kind of tibble: a grouped tibble. This class stores information that lets you know which rows are in which groups. The tidyverse functions, in particular the summarize function, are aware of the group information.

## 4.11.5 Create a tibble using `tibble()` instead of `data.frame` {#tibble}

It is sometimes useful for us to create our own data frames. To create a data frame in the tibble format, you can do this by using the **`tibble`** function.
```{r}
tibble(names = c("John", "Juan", "Jean", "Yao"),
       exam_1 = c(95, 80, 90, 85),
       exam_2 = c(90, 85, 85, 90)) -> grades
grades
```

# 4.12 The placeholder

One of the advantages of using the pipe |> is that we do not have to keep naming new objects as we manipulate the data frame. The object on the left-hand side of the pipe is used as the first argument of the function on the right-hand side of the pipe. <span class="blue">But what if we want to pass it as argument to the right-hand side function that is not the first?</span> The answer is the placeholder operator `_` **(for the `%>%` pipe the placeholder is `.`)**. Below is a simple example that passes the base argument to the log function. The following three are equivalent:
```{r}
log(8, base = 2)
2 |> log(8, base = _)
2 %>% log(8, base = .)
```

## 4.13 The purrr package

In Section 3.5 we learned about the <span id="sapply">`sapply`</span> function, which permitted us to apply the same function to each element of a vector. We constructed a function and used sapply to compute the sum of the first `n` integers for several values of `n` like this:

```{r}
compute_s_n <- function(n) {
  x <- 1:n
  sum(x)
}
n <- 1:25
s_n <- sapply(n, compute_s_n)
s_n
```
This type of operation, applying the same function or procedure to elements of an object, is quite common in data analysis. The **purrr** package includes functions similar to `sapply` but that better interact with other tidyverse functions. The main advantage is that we can better control the output type of functions. In contrast, `sapply` can return several different object types; for example, we might expect a numeric result from a line of code, but sapply might convert our result to character under some circumstances. **purrr** functions will never do this: they will return objects of a specified type or return an error if this is not possible.

The first purrr function we will learn is <span id="map">`map()`</span>, which works very similar to `sapply` but always, without exception, returns a list:

```{r}
library(purrr)
s_n <- map(n, compute_s_n)
class(s_n)
```
If we want a numeric vector, we can instead use <span id="map_dbl">`map_dbl`</span> which always returns a vector of numeric values.
```{r}
s_n <- map_dbl(n, compute_s_n)
class(s_n)
```
<span class="blue">This produces the same results as the sapply call shown above.</span>

A particularly useful **purrr** function for interacting with the rest of the tidyverse is `map_df`, which always returns a tibble data frame. However, the function being called needs to return a vector or a list with names. For this reason, the following code would result in a Argument 1 must have names error:

```{r}
# s_n <- map_df(n, compute_s_n)
```

<span class="blue">We need to change the function to make this work:</span>

```{r}
## compute_s_n <- function(n) {
##   x <- 1:n
##   sum(x)
##  }

compute_s_n <- function(n) {
  x <- 1:n
  tibble(sum = sum(x))
}
s_n <- map_df(n, compute_s_n)
s_n
```

# 4.14 Tidyverse conditionals

## 4.14.1 `case_when()` {#case_when}

The `case_when` function is useful for vectorizing conditional statements. It is similar to `ifelse` but can output any number of values, as opposed to just `TRUE` or `FALSE`. Here is an example splitting numbers into negative, positive, and 0:
```{r}
x <- c(-2, -1, 0, 1, 2)
case_when(x < 0 ~ "Negative",
          x > 0 ~ "Positive",
          TRUE ~ "Zero")
```
A common use for this function is to define categorical variables based on existing variables. For example, suppose we want to compare the murder rates in four groups of states: New England, West Coast, South, and other. For each state, we need to ask if it is in New England, if it is not we ask if it is in the West Coast, if not we ask if it is in the South, and if not we assign other. Here is how we use case_when to do this:

```{r}
murders |>
  mutate(group = case_when(
    abb %in% c("ME", "NH", "VT", "MA", "RI", "CT") ~ "New England",
    abb %in% c("WA", "OR", "CA") ~ "West Coast",
    region == "South" ~ "South",
    TRUE ~ "Other")) |>
  group_by(group) |>
  summarise(rate = sum(total) / sum(population) * 10^5)
```

## 4.14.2 `between()` {#between}

A common operation in data analysis is to determine if a value falls inside an interval. We can check this using conditionals. For example, to check if the elements of a vector x are between a and b we can type
```
x >= a
```
However, this can become cumbersome, especially within the tidyverse approach. The between function performs the same operation.
```
between(x, a, b)
```
# 4.15 Exercises

1. Load the murders dataset. Which of the following is true?
  a. murders is in tidy format and is stored in a tibble.
  b. murders is in tidy format and is stored in a data frame. TRUE
  c. murders is not in tidy format and is stored in a tibble.
  d. murders is not in tidy format and is stored in a data frame.

```{r}
murders
```


2. Use as_tibble to convert the murders data table into a tibble and save it in an object called murders_tibble.

```{r}
murders_tibble <- as_tibble(murders)
murders_tibble
```

3. Use the group_by function to convert murders into a tibble that is grouped by region.
```{r}
murders |>
  group_by(region)
```

4. Write tidyverse code that is equivalent to this code:

exp(mean(log(murders$population)))
Write it using the pipe so that each function is called without arguments. Use the dot operator to access the population. Hint: The code should start with murders |>.

```{r}
murders |>
  pull(population) |> 
  log() |>
  mean() |>
  exp()
```

5. Use the `map_df` to create a data frame with three columns named n, s_n, and s_n_2. The first column should contain the numbers 1 through 100. The second and third columns should each contain the sum of 1 through $n$ with $n$ the row number.
```{r}
n <- 1:100
summer <- function (n) {
  x <- 1:n
  tibble(sum = sum(x))
}
n <- 1:100
s_n <- map_df(n, summer)
s_n_2 <- map_df(n, summer)
my_df <- data.frame(
  n = n,
  s_n = s_n,
  s_n_2 = s_n_2
)
names(my_df) <- c("n", "s_n", "s_n_2")
my_df
```









